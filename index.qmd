---
title: Functional Phytoplankton Group Retrieval From Space
author:
  - name: Susanne E. Craig
    orcid: 0000-0002-0760-5497
    corresponding: true
    email: steve@curvenote.com
    roles:
      - Investigation
      - Project administration
    affiliations:
      - NASA
  - name: Erdem M. Karaköylü
    orcid: 0000-0002-7859-8394
    corresponding: true
    email: erdemk@protonmail.com
    roles:
      - Investigation
      - Software
      - Visualization
    affiliations:
      - Consultant
keywords:
  - Phytoplankton Functional Groups (PFGs)
  - Hyperspectral Ocean Color
  - Remote Sensing of Phytoplankton
  - Chlorophyll-a Retrieval
  - PACE Mission

abstract: |
  In September 2021, a significant jump in seismic activity on the island of La Palma (Canary Islands, Spain) signaled the start of a volcanic crisis that still continues at the time of writing. Earthquake data is continually collected and published by the Instituto Geográphico Nacional (IGN). ...
plain-language-summary: |
  Earthquake data for the island of La Palma from the September 2021 eruption is found ...
key-points:
  - A web scraping script was developed to pull data from the Instituto Geogràphico Nacional into a machine-readable form for analysis
  - Earthquake events on La Palma are consistent with the presence of both mantle and crustal reservoirs.
date: last-modified
bibliography: references.bib
citation:
  container-title: Earth and Space Science
number-sections: true
jupyter: python3
---

## Introduction

Phytoplankton functional groups (PFGs) play a fundamental role in marine biogeochemical cycles, influencing carbon sequestration, nutrient fluxes, and global climate feedbacks. Different functional groups contribute uniquely to these processes; for example, diatoms facilitate carbon export through rapid sinking, cyanobacteria fix atmospheric nitrogen, and coccolithophores regulate carbonate chemistry via calcification [@Maranon2015; @Boyd2010]. Identifying and quantifying these groups from space is crucial for understanding their ecological functions, detecting environmental changes, and improving ocean biogeochemical models [@Bopp2005; @Laufkotter2015]. However, current satellite ocean-color products primarily provide total chlorophyll-*a* concentrations, which do not directly indicate community composition. To address this gap, various remote sensing algorithms have been developed to infer phytoplankton diversity, each with limitations in distinguishing certain groups and quantifying their biomass accurately [@Mouw2017].

### Remote Sensing Approaches for PFG Retrieval

Phytoplankton classification from satellite remote sensing has traditionally relied on empirical and semi-analytical methods. Empirical band-ratio techniques, such as PHYSAT, classify dominant phytoplankton groups based on anomalies in spectral reflectance but are often region-specific and limited to broad functional classes [@Alvain2005; @Alvain2008]. Semi-analytical models, in contrast, use inherent optical properties (IOPs) to infer phytoplankton composition from satellite reflectance, providing a more mechanistic approach [@Hirata2011]. Hybrid models incorporate additional environmental variables, such as sea surface temperature and total chlorophyll, to infer community structure [@Brewin2010].

More recently, hyperspectral ocean-color sensors, such as NASA’s upcoming Plankton, Aerosol, Cloud, ocean Ecosystem (PACE) mission, have been designed to improve PFG retrieval by capturing finer spectral features associated with phytoplankton pigments [@Dierssen2023]. These advancements offer the potential for enhanced classification, yet challenges remain. Optical similarity between different groups, depth-related biases in surface measurements, and uncertainties in algorithm parameterization continue to limit retrieval accuracy [@IOCCG2014]. Most current models either estimate phytoplankton size classes or assign a single dominant group per pixel, often failing to capture the complexity of mixed communities [@Ciotti2002].

### Study Contribution and Approach

In this study, we introduce **extreme gradient boosting (XGBoost)** as a novel approach for retrieving phytoplankton functional groups from satellite ocean color data. XGBoost is a scalable ensemble learning algorithm that has demonstrated high performance in complex classification tasks but has not yet been widely applied to PFG retrieval [@Chen2016]. Unlike traditional empirical and semi-analytical models, our method leverages a large dataset of simulated hyperspectral reflectance and environmental variables to improve both the discrimination of functional groups and the quantification of their biomass. Previous remote sensing algorithms often classified only a dominant PFG or broad size class [@Mouw2017] and relied on empirical band relationships that lacked generalizability [@Hirata2011]. By utilizing a machine learning framework capable of integrating multiple features, our approach reduces classification errors and enhances retrieval precision.

Recent studies have demonstrated the potential of XGBoost in related applications, such as harmful algal bloom detection [@Izadi2021] and phytoplankton biomass estimation [@Yan2025], highlighting its suitability for remote sensing applications. Our work aligns with the objectives of the PACE mission by contributing an advanced classification algorithm that enhances hyperspectral monitoring of phytoplankton diversity [@Zhang2024]. To our knowledge, this is the first application of XGBoost for PFG classification in ocean color remote sensing, offering a robust alternative to traditional retrieval methods.


## Methods

### Data Preparation and Feature Selection

We utilized a simulated dataset representing the world ocean over 31 days, corresponding to December 2021. The simulation generated hyperspectral remote sensing reflectance (Rrs) data, emulating a sensor configuration akin to that of the PACE instrument. Due to the high dimensionality of the original spectral data, we conducted an initial exploratory analysis and observed strong correlations among many of the channels. To reduce redundancy while preserving essential spectral information, we retained 51 channels by selecting one channel every ten. We opted against applying principal component analysis (PCA) because preliminary investigations indicated that PCA tended to overemphasize the signal from extensive blue water areas, which could mask coastal processes of interest. In addition to these 51 spectral channels, we included auxiliary environmental variables such as temperature and latitude.

The dataset was divided into training and test sets using an 80/20 split. The training set was exclusively used for model development and hyperparameter optimization, while the test set was reserved for the final validation of model performance.

### Modeling and Hyperparameter Optimization

We employed an XGBoost Regressor model wrapped within a multi-output regression structure to simultaneously predict multiple phytoplankton functional groups as well as total chlorophyll-*a* concentration. XGBoost is a high-performance, scalable implementation of gradient boosting that has become a popular choice for a wide range of regression and classification tasks [@Chen2016]. It builds an ensemble of decision trees sequentially, where each new tree attempts to correct the errors made by the previous trees. By optimizing a regularized objective function, XGBoost effectively controls overfitting while enhancing prediction accuracy. Its efficient handling of sparse data, support for parallel computation, and flexible regularization mechanisms make it particularly well-suited for complex modeling tasks, such as predicting multiple phytoplankton functional groups and total chlorophyll-*a* concentration from hyperspectral and ancillary oceanographic data.

Given the complexity of the problem and the high dimensionality of the input features, it was critical to optimize the hyperparameters to achieve robust performance and prevent overfitting. To this end, we conducted hyperparameter optimization using a Bayesian optimization approach[@Snoek2012] implemented with Optuna[@Akiba2019]. The objective function minimized the root mean squared error (RMSE) computed via three-fold cross-validation on the training set. The hyperparameters under investigation included the learning rate, maximum tree depth, number of estimators, subsample ratio, column subsample ratio, and gamma (the minimum loss reduction required to make a further partition on a leaf node). The Bayesian optimization procedure allowed us to efficiently explore the hyperparameter space by leveraging past trial information to prune unpromising candidates early, thereby reducing overall computational cost.

### Model Evaluation and eXplainable AI (XAI)
Once the optimal hyperparameter combination was identified, we retrained the final XGBoost model on the full training set using these optimized settings. Finally, we evaluated the performance of the retrained model on the held-out test set to assess its generalizability.


#### XAI with SHAP

To enhance interpretability and gain insights into how different input features influence model predictions, we employed **Shapley Additive Explanations (SHAP)**, a widely used explainable AI (XAI) framework for interpreting complex machine learning models. SHAP is named after the concept of Shapley values, which consists in assigning importance values to each input feature by estimating its contribution to the model's predictions across different samples. The method is rooted in cooperative game theory, ensuring a fair distribution of importance scores among features [@Lundberg2017].

Given the computational complexity of our XGBoost model and the high dimensionality of the dataset, we conducted SHAP analysis on a **random subsample of 1,000 observations from the test set**. This subset was selected to balance computational feasibility while maintaining a representative sample of phytoplankton spectral diversity.

We generated **SHAP summary plots**, which provide a comprehensive visualization of feature importance and the directionality of their influence on model outputs. These plots display the magnitude of each feature's impact across all predictions, helping to identify the most influential spectral and environmental variables in determining phytoplankton functional group composition. The insights gained from SHAP analysis aid in validating model behavior and ensuring its ecological plausibility.


##### Code Availability
All code used in this study is publicly available on GitHub ([GitHub repository URL]).


## Results

### Hyperparameter Optimization (HPO)

We performed hyperparameter optimization using a Bayesian optimization framework implemented with Optuna. The metric used for optimization was the average RMSE (in units of $mgL^{-1} Chl_a$ ) computed over the cross-validation folds and across all target compartments. The “full HPO run” best parameters indicate a relatively aggressive model, characterized by deep trees with many estimators, a moderate learning rate, and little regularization via gamma.

The best trial finished with an RMSE of $0.116mgL^{-1} Chl_a$. Below is the list of hyperparameters researched, the optimal values found, and an interpretation of these values:

*  Learning Rate (learning_rate): $0.083$ - This moderate learning rate suggests the model takes reasonably sized steps when updating that are neither too aggressive (which might lead to overshooting the optimum) nor too conservative (which could slow down convergence). 

* Max Depth (max_depth): $10$ - A depth of 10 allows the trees to capture complex interactions. This may indicate that the data has non-linear relationships that benefit from deeper trees. Such a depth can be associated with overfitting. The cross-validation process during HPO should minimize this however.

* Number of Estimators (n_estimators): $466$ -Building around 466 trees indicates the ensemble haa to tackle inherent complexity in the data that was not apparetn during the Exploratory Data Analysis phase. A larger number of trees generally improves performance—up to a point before overfitting becomse a risk.  This number in conjunction with the cross validation process suggest this number strikes a balance between performance and overfitting.

* Subsampling (subsample): $0.658$ - This indicates each of the 466 trees is using roughly 66% of the data. This introduces randomness that helps prevent overfitting as not all samples in any cross-validation fold are used to build every tree.

* Features used per tree (colsample_bytree): $0.894$ - Using about 89% of the features per tree indicates that most features are informative, and the model is allowed to consider almost the full feature set at each split. - See features used in the Methods section.
    
* Gamma (gamma): $8.63e-06$ - An extremely low gamma value means that almost no minimum loss reduction is required to make a split. This implies that the algorithm will split more readily, potentially capturing fine details. Awareness of this hyperparameter values is important as low gamma  can risk overfitting.


### Optimized Model Validation

The next step was to load the best set of hyperparameter (listed above) into the model and retrain the model on the entire training set. The optimized and trained model was then validated using the test set, which prior to the HPO process and until this step had been set aside . This validation step ensured that the model performed satisfactorily on unseen data and was ready for prediction on new data. The following performance metrics were recorded during validation:

- **Mean Squared Error (MSE):**  
  MSE is the average of the squared differences between the predicted and true values. Squaring the errors emphasizes larger deviations, making MSE sensitive to outliers. In our context, MSE is expressed in units of (mg L$^{-1}$ Chl$_a$)$^2$. Lower MSE values indicate better model performance.

- **Root Mean Squared Error (RMSE):**  
  RMSE is the square root of the MSE, bringing the error metric back to the original units (mg L$^{-1}$ Chl$_a$). It provides a direct measure of the average prediction error magnitude. Lower RMSE values suggest that the model’s predictions are closer to the true values.

- **Mean Absolute Error (MAE):**  
  MAE calculates the average absolute difference between predicted and true values. Unlike MSE, it does not square the errors, so it is less sensitive to large outliers. MAE is also expressed in the same units as the target variable (mg L$^{-1}$ Chl$_a$). A lower MAE indicates better predictive accuracy.

- **Coefficient of Determination (R-squared):**  
  R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variables. It ranges from 0 to 1, where a value closer to 1 indicates that the model explains a high proportion of the variance in the data. In our results, high R-squared values generally indicate strong model performance, although lower values (e.g., for dinoflagellates) suggest room for improvement.

- **MAE/StDev$_{true}$:**  
  This ratio compares the mean absolute error to the standard deviation of the true values. It provides a relative measure of error by indicating how the average error compares to the inherent variability in the data. A lower ratio implies that the model’s prediction error is small relative to the natural variability of the observations.

  After retraining the final model using the best hyperparameters identified during hyperparameter optimization, we evaluated its performance on the held-out test set. The following metrics were computed for each target output (with units in $mg L^{-1} Chl_a in the case of RMSE and MAE):


### Conclusion

### References {.unnumbered}

::: {#refs}
:::